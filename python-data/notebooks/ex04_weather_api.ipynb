{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise: Weather API\n",
    "\n",
    "## Aim: Use a Weather API to create and graph NetCDF files\n",
    "\n",
    "### Issues covered:\n",
    "\n",
    "- Request and get data from a weather API service\n",
    "- Read and retrieve information from a JSON response\n",
    "- Write contents to a NetCDF file\n",
    "- Read a collection of NetCDF files and plot a time series graph\n",
    "\n",
    "## 1. Let's get data from a web API on the internet\n",
    "\n",
    "We will use the NOAA National Weather Service in the US as our data source:\n",
    "\n",
    "![](https://www.weather.gov/css/images/header.png)\n",
    "\n",
    "The service has a web API that allows you to request forecast data for a given grid point in the USA. Details of the API are documented at:\n",
    "\n",
    "https://www.weather.gov/documentation/services-web-api\n",
    "\n",
    "Use the endpoint `https://api.weather.gov/` as the base URL.\n",
    "\n",
    "Firstly, we want to get a grid ID and based on some latitude/longitude coordinates. To do so we will use the `points/{latitude,longitude}` endpoint of the API.\n",
    "\n",
    "**Choose the latitude and longitude of your favourite US location (this API is US only and in latitude North, longitude East). The extent of the USA is approximately:**\n",
    "- Longitude: -120, -80\n",
    "- Latitude:  30, 48\n",
    "\n",
    "Once you have queried the `points` API you will get back a `grid ID` (`GridId`). The `grid ID`h can be used to get a weather forecast for your location of interest, using the `gridpoints/{grid ID}/{grid co-ordinates}` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `requests` library which is great for downloading content from external URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# longitude:-122.485417, latitude:37.859306\n",
    "# https://api.weather.gov/points/37.8593,-122.4854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use the requests library to access the web API. Fill in the elipses with the `latitude` (degrees North) and `longitude` (degrees East, so use negative value) of a location in the US. \n",
    "If successful, the response code should be 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.weather.gov/'\n",
    "latitude = 37.859306\n",
    "longitude = -122.485417\n",
    "\n",
    "# Hint: use the requests library to GET from the url: https://api.weather.gov/points/{LAT},{LON}\n",
    "response = requests.get(f'{url}points/{latitude},{longitude}')\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)\n",
    "# We want the content from response that's in json format i.e.\n",
    "# rep = response.json()\n",
    "# type(rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the requests library, the results from the webAPI can be extracted into in JSON format. A JSON document behaves exactly like a dictionary.\n",
    "\n",
    "Use dictionary indexing to extract the values of the grid ID and the X/Y coordinates:\n",
    "\n",
    "- get `gridID`\n",
    "- get `gridX`\n",
    "- get `gridY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTR 83 109\n"
     ]
    }
   ],
   "source": [
    "# hint: you can view the JSON by pasting the URL directly into your browser address bar\n",
    "\n",
    "#response = response.json()  # This reads the request as json and decodes it into a dictionary\n",
    "rep = response.json() \n",
    "\n",
    "assert \"properties\" in rep # Check that rep contains what we expect\n",
    "\n",
    "#type(d)\n",
    "#d.keys()\n",
    "#d['geometry']\n",
    "#d['geometry'].keys()   # Call keys method on the dictionary\n",
    "#d['geometry']['coordinates']\n",
    "#type(d['geometry']['coordinates'])   # number of square brackets tells you the dimensions\n",
    "#d['geometry']['coordinates'][0][3][0]\n",
    "\n",
    "# The json file contains \n",
    "#print(response[\"properties\"][\"gridId\"])\n",
    "\n",
    "gridID = rep[\"properties\"][\"gridId\"]    # gridID is part of a dictionary in the properties list?? key, number\n",
    "gridX = rep[\"properties\"][\"gridX\"]\n",
    "gridY = rep[\"properties\"][\"gridY\"]\n",
    "\n",
    "# Alternatively you could write as follows\n",
    "#props = rep[\"properties\"]\n",
    "#gridID = props[\"gridId\"]   \n",
    "#gridX = props[\"gridX\"]\n",
    "#gridY = props[\"gridY\"]\n",
    "\n",
    "print(gridID,gridX,gridY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your `gridID`, `gridX`, and `gridY`, use the `gridpoints` API endpoint to request a weather forecast for that location. Print the status code.\n",
    "If everything is working, you should get another 200 status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(f'{url}gridpoints/{gridID}/{gridX},{gridY}')\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you use the JSON response data to get the forecast temperature values? Use dictionary indexing to get the `values` from `temperature` in `properties`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['@context', 'id', 'type', 'geometry', 'properties'])\n",
      "<class 'dict'>\n",
      "dict_keys(['@id', '@type', 'updateTime', 'validTimes', 'elevation', 'forecastOffice', 'gridId', 'gridX', 'gridY', 'temperature', 'dewpoint', 'maxTemperature', 'minTemperature', 'relativeHumidity', 'apparentTemperature', 'wetBulbGlobeTemperature', 'heatIndex', 'windChill', 'skyCover', 'windDirection', 'windSpeed', 'windGust', 'weather', 'hazards', 'probabilityOfPrecipitation', 'quantitativePrecipitation', 'iceAccumulation', 'snowfallAmount', 'snowLevel', 'ceilingHeight', 'visibility', 'transportWindSpeed', 'transportWindDirection', 'mixingHeight', 'hainesIndex', 'lightningActivityLevel', 'twentyFootWindSpeed', 'twentyFootWindDirection', 'waveHeight', 'wavePeriod', 'waveDirection', 'primarySwellHeight', 'primarySwellDirection', 'secondarySwellHeight', 'secondarySwellDirection', 'wavePeriod2', 'windWaveHeight', 'dispersionIndex', 'pressure', 'probabilityOfTropicalStormWinds', 'probabilityOfHurricaneWinds', 'potentialOf15mphWinds', 'potentialOf25mphWinds', 'potentialOf35mphWinds', 'potentialOf45mphWinds', 'potentialOf20mphWindGusts', 'potentialOf30mphWindGusts', 'potentialOf40mphWindGusts', 'potentialOf50mphWindGusts', 'potentialOf60mphWindGusts', 'grasslandFireDangerIndex', 'probabilityOfThunder', 'davisStabilityIndex', 'atmosphericDispersionIndex', 'lowVisibilityOccurrenceRiskIndex', 'stability', 'redFlagThreatIndex'])\n",
      "<class 'dict'>\n",
      "dict_keys(['uom', 'values'])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "\n",
    "print(type(data))                                         # <class 'dict'>\n",
    "print(data.keys())                                        # dict_keys(['@context', 'id', 'type', 'geometry', 'properties'])\n",
    "print(type(data['properties']))\n",
    "print(data['properties'].keys())\n",
    "print(type(data['properties']['temperature']))\n",
    "print(data['properties']['temperature'].keys())\n",
    "print(type(data['properties']['temperature']['values']))  # <class 'list'>\n",
    "#print((data['properties']['temperature']['values']))\n",
    "\n",
    "forecast = data['properties']['temperature']['values']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code extracts the coordinates of the grid box you have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = data['geometry']['coordinates'][0][0]\n",
    "x = coords[1]\n",
    "y = coords[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's format that data and write it to NetCDF\n",
    "\n",
    "### Formatting the data\n",
    "\n",
    "First, format your forecast data to get the datetime and air temperature as separate\n",
    "lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt         # the datetime module contains a class called datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through your `forecast` values and get the temperatures (`value`) and datetimes (`validTime`) into a list.\n",
    "`forecast` is a list of dictionaries, where each dictionary is of one time instance.\n",
    "Fill in the ellipses to format each `validTime` string to a python `datetime` object and assign and set to the variable `date`. Get each `value` and assign to the variable `temp`. These values will then be appended to the `temps` and `timeseries` lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the datetime module to convert the times from the data to a datetime object.\n",
    "# Hint: look at the validTime string and see how you can turn the string to datetime\n",
    "# using strptime, the format of the datetime is: '%Y-%m-%dT%H:%M:%Sz'.\n",
    "\n",
    "timeseries = []\n",
    "temps = []\n",
    "\n",
    "# 'forecast' is a list of dictionaries, where each dictionary is of one time instance\n",
    "for item in forecast:\n",
    "    #print(item)\n",
    "    # Extract time and temp from the forecast dictionary:\n",
    "    date, temp = item['validTime'], item['value']  \n",
    "    # Split the date string at the '/' character to remove \n",
    "    date = dt.strptime(date.split(sep='/')[0], '%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "    # call datetime (dt) class and strptime module\n",
    "    \n",
    "    #print(date)\n",
    "    #print(temp)\n",
    "    timeseries.append(date)\n",
    "    temps.append(temp)\n",
    "\n",
    "#help(dt)\n",
    "#dir(d)                        # Lists the methods available (e.g. split)\n",
    "#help(d.split)                 # Provides info on a specific method\n",
    "#print(d.split(sep='/')[0])\n",
    "#d.split(sep='/')[0]\n",
    "\n",
    "#print(timeseries)\n",
    "#print(temps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the `timeseries` list and convert it to relative time in seconds from the start of the timeseries. When using NetCDF and the CF Metadata Conventions time is stored as an offset from a base time rather than an absolute times.\n",
    "\n",
    "If you are stuck, take look at the 'Time series' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_time = timeseries[0]\n",
    "time_values = []\n",
    "\n",
    "#for t in timeseries:\n",
    "#    ...\n",
    "#\n",
    "#time_units = ...\n",
    "\n",
    "for t in timeseries:\n",
    "    value = t - base_time\n",
    "    ts = value.total_seconds()\n",
    "    time_values.append(ts)\n",
    "\n",
    "time_units = \"seconds since \" + base_time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n",
      "<class 'datetime.timedelta'>\n",
      "Help on built-in function total_seconds:\n",
      "\n",
      "total_seconds(...) method of datetime.timedelta instance\n",
      "    Total seconds in the duration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = timeseries[0]\n",
    "t1 = timeseries[1]\n",
    "delta = t1-t0\n",
    "print(type(t0))\n",
    "print(type(delta))\n",
    "help(delta.total_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert the `temps` list from degrees C to Kelvin. As per the CF Conventions, the canonical units for Air Temperature is K. Create a new list, called `temp_values`, which is the temperature in Kelvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp_values = []\n",
    "\n",
    "for t in temps:\n",
    "    # Convert \n",
    "    temp = t + 273.15\n",
    "    temp_values.append(temp)     # Use append method to add a value\n",
    "\n",
    "# Alternatively you can write this on one line as a list comprehension\n",
    "# Start with empty list\n",
    "# On the right-hand side put in condition (e.g. a for loop)\n",
    "# On the left-hand side put the action \n",
    "# at end of list put for loop and at start of list with action\n",
    "# temp_value = [{action} {for loop}]\n",
    "\n",
    "temp_value = [temp + 273.15 for t in temps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a netCDF4 Dataset and write the contents to a file\n",
    "\n",
    "Import the `Dataset` class from the `netCDF4` library. You can go on to create an *instance* of this class which will contain:\n",
    "- variables\n",
    "- coordinate variables\n",
    "- dimensions\n",
    "- global attributes\n",
    "\n",
    "When you create the instance of `Dataset`, you will give it a file name which will be written to when you close the `Dataset`.\n",
    "\n",
    "Also import `numpy` as `np`. This will be used to construct the data arrays from the existing lists that currently hold the weather data and coordinate information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick aside, let's make sure we have a `DATA_DIR` to write to\n",
    "\n",
    "Since this is a group exercise, everyone should be writing to the same output directory. Let's set some python variables that can be used below:\n",
    "1. `USER` - used in the output file names to ensure every NetCDF file is unique.\n",
    "2. `HOME_DIR` - your `$HOME` directory\n",
    "2. `MY_DATA_DIR` - the directory where you will write your NetCDF file.\n",
    "3. `GROUP_DATA_DIR` - the directory where all the NetCDF files will eventually be collected/available.\n",
    "\n",
    "Since `GROUP_DATA_DIR` is not writeable directly from the Notebook Service, we have set up a job to replicate files from `MY_DATA_DIR` to `GROUP_DATA_DIR` (which runs once per minute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "USER = os.environ[\"JUPYTERHUB_USER\"]\n",
    "\n",
    "HOME_DIR = f\"/home/users/{USER}\"\n",
    "MY_DATA_DIR = os.path.join(HOME_DIR, \"weather-api-outputs\")\n",
    "\n",
    "# Create MY_DATA_DIR if it doesn't exist\n",
    "if not os.path.isdir(MY_DATA_DIR):\n",
    "    os.mkdir(MY_DATA_DIR)\n",
    "\n",
    "# All NetCDF will be automatically copied here (once per minute)\n",
    "GROUP_DATA_DIR = \"/gws/pw/j07/workshop/weather-api-data\"\n",
    "\n",
    "# The output file will initially be written to your HOME_DIR (then you will move\n",
    "# it when complete)\n",
    "filename = f\"{gridID}-{USER}-temps.nc\"\n",
    "outfile = f\"{HOME_DIR}/{filename}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to our NetCDF file\n",
    "\n",
    "Create the output file, as a `netCDF4 Dataset` instance, using the `outfile` defined above.\n",
    "\n",
    "If you need help, have a look at the 'Create the NetCDF dimensions & variables' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(outfile, 'w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start by defining some dimensions\n",
    "\n",
    "Create NetCDF *dimensions*:\n",
    "- `time_dim`: *unlimited* length\n",
    "- `lat_dim`: length 1\n",
    "- `lon_dim`: length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dim = dataset.createDimension('time', None)\n",
    "lat_dim = dataset.createDimension('lat', 1)\n",
    "lon_dim = dataset.createDimension('lon', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now define the coordinate variables and then temperature variable\n",
    "\n",
    "Create the `time` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `time`\n",
    "- dimensions: (`time`,)\n",
    "- set the array using the `time_values` list\n",
    "- `units`: `time_units` defined earlier\n",
    "- `standard_name`: `time`\n",
    "- `calendar`: `standard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = dataset.createVariable('time', np.float64, ('time',)) # Set up variable name, type, and dimensions\n",
    "time_var[:] = time_values                                            # Assign the values to time_var\n",
    "time_var.units = time_units\n",
    "time_var.standard_name = 'time'\n",
    "time_var.calendar = 'standard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `lat` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `lat`\n",
    "- dimensions: (`lat`,)\n",
    "- set the array of length 1 using the `gridY` value\n",
    "- `units`: `degrees_north`\n",
    "- `standard_name`: `latitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_var = dataset.createVariable('lat', np.float64, ('lat',)) \n",
    "lat_var[:] = gridY\n",
    "lat_var.units = 'degrees_north'\n",
    "lat_var.standard_name = 'latitude'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `lon` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `lon`\n",
    "- dimensions: (`lon`,)\n",
    "- set the array of length 1 using the `gridX` value\n",
    "- `units`: `degrees_east`\n",
    "- `standard_name`: `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_var = dataset.createVariable('lon', np.float64, ('lon',)) \n",
    "lon_var[:] = gridX\n",
    "lon_var.units = 'degrees_east'\n",
    "lon_var.standard_name = 'longitude'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `temp` *variable* with the following properties:\n",
    "- type: numpy float (`np.float64`)\n",
    "- variable id: `temp`\n",
    "- dimensions: (`time`,)\n",
    "- set the array using the `temp_values` list\n",
    "- `long_name`: `air temperature (K)`\n",
    "- `units`: `K`\n",
    "- `standard_name`: `air_temperature`\n",
    "- `coordinates`: `lon lat` - to relate the longitude and latitude to this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_var = dataset.createVariable('temp', np.float64, ('time',))\n",
    "temp_var[:] = temp_values\n",
    "temp_var.var_id = 'temp'\n",
    "temp_var.long_name = 'air temperature (K)'\n",
    "temp_var.units = 'K'\n",
    "temp_var.standard_name = 'air_temperature'\n",
    "temp_var.coordinates = 'lon lat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add some global attributes\n",
    "\n",
    "The [CF Metadata Conventions](https://cfconventions.org/cf-conventions/cf-conventions.html#_overview) recommends a set of global attributes to \"provide human readable documentation of the file contents\":\n",
    "- title\n",
    "- history\n",
    "- institution\n",
    "- source\n",
    "- references\n",
    "- comment\n",
    "\n",
    "Add each of the above to your `Dataset` instance. Here are some suggested values (but you can say whatever you like):\n",
    "- title: Air Temperature forecasts for `<gridID>`\n",
    "- history: File created on: `<YYYY-MM-DD>`\n",
    "- institution: NCAS-ISC\n",
    "- source: NOAA Weather API Service\n",
    "- references: https://www.weather.gov/documentation/services-web-api\n",
    "- comment: The ISC course is teaching me about Python and NetCDF!\n",
    "\n",
    "You can add any other global attributes that you wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:49:39.319853\n"
     ]
    }
   ],
   "source": [
    "dataset.title = f'Air Temperature forecasts for {gridID}'\n",
    "print(dt.now())\n",
    "type(dt.now())\n",
    "#help(dt)\n",
    "#cdate = dt.strptime(dt.now(), '%Y-%m-%dT%H:%M:%S%z')\n",
    "dataset.history = f'File created on: {dt.now().strftime(\"%Y-%m-%d\")}'\n",
    "dataset.institution = 'NCAS-ISC'\n",
    "dataset.source = 'NOAA Weather API Service'\n",
    "dataset.references = 'https://www.weather.gov/documentation/services-web-api'\n",
    "dataset.comment = 'The ISC course is teaching me about Python and NetCDF!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, close the `Dataset` to save the file\n",
    "\n",
    "Save your NetCDF file by closing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check it is there using `os.path.isfile(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Move the file to your MY_DATA_DIR so it gets copied to the GROUP_DATA_DIR\n",
    "\n",
    "Since we cannot write directly to the `GROUP_DATA_DIR`, move the file from your `HOME_DIR` to your `MY_DATA_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(outfile, f\"{MY_DATA_DIR}/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Find all the NetCDF files written during this exercise\n",
    "\n",
    "To find all the `.nc` files in a group workspace, we will use the glob module in Python.\n",
    "Glob let's us find all files matching a pattern, in our case:\n",
    "\n",
    "`{GROUP_DATA_DIR}/*.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can you use glob to make a list of file paths of all NetCDF files in the\n",
    "group workspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gws/pw/j07/workshop/weather-api-data/TOP-train041-temps.nc', '/gws/pw/j07/workshop/weather-api-data/MLB-train024-temps.nc', '/gws/pw/j07/workshop/weather-api-data/HGX-train015-temps.nc', '/gws/pw/j07/workshop/weather-api-data/TOP-train022-temps.nc', '/gws/pw/j07/workshop/weather-api-data/EAX-train041-temps.nc', '/gws/pw/j07/workshop/weather-api-data/TOP-train008-temps.nc', '/gws/pw/j07/workshop/weather-api-data/FFC-train030-temps.nc', '/gws/pw/j07/workshop/weather-api-data/FGZ-train016-temps.nc', '/gws/pw/j07/workshop/weather-api-data/RIW-train012-temps.nc']\n"
     ]
    }
   ],
   "source": [
    "filepaths = glob(f\"{GROUP_DATA_DIR}/*temps.nc\")\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Create a time-series graph of all the forecasts\n",
    "\n",
    "Now that we have a list of NetCDF file paths, we can open them and extract their data.\n",
    "\n",
    "To start, let us make the a plot using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import num2date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a subplots figure with figure and axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Can you set the x-axis locator (ticks) using dates class from matplotlib?\n",
    "- set the major locator to days.\n",
    "- set the minor locator to every 6 hours.\n",
    "- set the x-axis formatter to Day-Month for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# In the matplotlib.dates module, as mdates, look at the DayLocator and HourLocator.\n",
    "#help(mdates)  # help on module\n",
    "#* `HourLocator`: Locate hours.\n",
    "#* `DayLocator`: Locate specified days of the month.\n",
    "\n",
    "fmt_day = mdates.DayLocator()\n",
    "fmt_six_hours = mdates.HourLocator(interval=6)\n",
    "\n",
    "ax.xaxis.set_major_locator(fmt_day)\n",
    "ax.xaxis.set_minor_locator(fmt_six_hours)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Label the axis, `ax`, on the plot:\n",
    "- label the x-axis as `Date`\n",
    "- label the y-axis as `Air Temperature / K`\n",
    "- set a title on your plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Air Temperature Plot')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Air Temperature / K')\n",
    "ax.set_title('Air Temperature Plot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Open each NetCDF file and extract the `temp`, `time`, `lat` and `lon` variables from the file. Then use the matplotlib `plot_date` function to plot the graph.\n",
    "\n",
    "- set the label of plot to the `<lat>, <lon>` coordinates attribute of the `temp` variable.\n",
    "\n",
    "Replace the elipses with your plotting, the `for` loop works through all the shared NetCDF files in the workspace, where `f` is the file path and `filepaths` is a list of data files.\n",
    "\n",
    "If you need help, look at the 'Plotting data with matplotlib' slide in the [logging data from serial ports](https://github.com/ncasuk/ncas-isc/raw/68abbfd3a573e576c32fc127fafc874bfff98b1e/python/presentations/logging-data-from-serial-ports/LDFSP_Slides.pdf) presentation.\n",
    "\n",
    "Plot a line graph using matplotlib: \n",
    "\n",
    "- you will need to set the marker to `-` otherwise you will get a scatter graph.\n",
    "- set the label of the plot to a string: `<lat>, <lon>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n",
      "NETCDF4_CLASSIC\n",
      "['time', 'lat', 'lon']\n",
      "['time', 'lat', 'lon', 'temp']\n"
     ]
    }
   ],
   "source": [
    "for f in filepaths:\n",
    "    data = Dataset(f)  # read file\n",
    "    print(data.file_format)\n",
    "    print(list(dataset.dimensions.keys()))\n",
    "    print(list(dataset.variables.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, show the plot with a legend, you might want to enable tight layout,\n",
    "and save the plot to your `MY_DATA_DIR` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the graph to a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{MY_DATA_DIR}/{gridID}-{USER}-temps.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
